{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "db = \"new_db.db\"\n",
    "con = sqlite3.connect(db)\n",
    "cur = con.cursor()\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    emails = list(cur.execute(\"\"\"SELECT (\n",
    "                                    COALESCE(email_from, '') || ' ' ||\n",
    "                                    COALESCE(email_to, '') || ' ' ||\n",
    "                                    COALESCE(email_cc, '') || ' ' ||\n",
    "                                    COALESCE(email_bcc, '') || ' ' ||\n",
    "                                    COALESCE(email_subject, '') || ' ' ||\n",
    "                                    COALESCE(email_message, '')\n",
    "                                )\n",
    "\n",
    "                                FROM emails_main\n",
    "                                WHERE folder_directory IS NOT NULL\"\"\"))\n",
    "\n",
    "    emails = [item[0] for item in emails]\n",
    "\n",
    "    emails_folder = list(cur.execute(\"\"\"SELECT folder_directory \n",
    "                                        FROM emails_main\n",
    "                                        WHERE folder_directory IS NOT NULL\"\"\"))\n",
    "\n",
    "    emails_folder = [item[0] for item in emails_folder]\n",
    "\n",
    "    emails_tobeprocessed = list(cur.execute(\"\"\"SELECT (\n",
    "                                                COALESCE(email_from, '') || ' ' ||\n",
    "                                                COALESCE(email_to, '') || ' ' ||\n",
    "                                                COALESCE(email_cc, '') || ' ' ||\n",
    "                                                COALESCE(email_bcc, '') || ' ' ||\n",
    "                                                COALESCE(email_subject, '') || ' ' ||\n",
    "                                                COALESCE(email_message, '')\n",
    "                                            )\n",
    "\n",
    "                                            FROM emails_main\n",
    "                                            WHERE folder_directory IS NULL\"\"\"))\n",
    "\n",
    "    emails_tobeprocessed = [item[0] for item in emails_tobeprocessed]\n",
    "\n",
    "    emails_tobeprocessed_messageid = list(cur.execute(\"\"\"SELECT message_id\n",
    "                                                         FROM emails_main\n",
    "                                                         WHERE folder_directory IS NULL\"\"\"))\n",
    "\n",
    "    emails_tobeprocessed_messageid = [item[0] for item in emails_tobeprocessed_messageid]\n",
    "\n",
    "    emails_tobeprocessed_tuple = list(zip(emails_tobeprocessed_messageid, emails_tobeprocessed))\n",
    "\n",
    "    X_train = emails\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    labelencoder.fit(emails_folder)\n",
    "    labelencoder_dict = dict(zip(labelencoder.classes_, labelencoder.transform(labelencoder.classes_)))\n",
    "\n",
    "    y_train = labelencoder.transform(emails_folder)\n",
    "\n",
    "    from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer, CountVectorizer\n",
    "\n",
    "    vectorizer = HashingVectorizer()\n",
    "    vectorizer.fit(X_train)\n",
    "\n",
    "    with open('vectorizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(vectorizer, handle)\n",
    "\n",
    "    X_train = vectorizer.transform(X_train)\n",
    "\n",
    "    X_predict = [email[1] for email in emails_tobeprocessed_tuple]\n",
    "    X_predict = vectorizer.transform(X_predict)\n",
    "\n",
    "    # OneClassSVM - to weed out outliers\n",
    "    from sklearn.svm import OneClassSVM\n",
    "    oneclasssvm = OneClassSVM()\n",
    "    oneclasssvm.fit(X_train)\n",
    "    oneclass_preds = list(oneclasssvm.predict(X_predict))\n",
    "\n",
    "    # Get indexes of outliers\n",
    "    # Outliers = -1, Inliers = 1\n",
    "    outliers_indexes = [i for i,x in enumerate(oneclass_preds) if x == -1]\n",
    "\n",
    "    if len(oneclass_preds) != len(outliers_indexes):\n",
    "\n",
    "        # Delete the outliers, in reverse order so it doesn't throw off the subsequent indexes\n",
    "        for index in sorted(outliers_indexes, reverse=True):\n",
    "            del emails_tobeprocessed_tuple[index]\n",
    "\n",
    "        # New value for X_predict after deletion of outliers\n",
    "        X_predict = [email[1] for email in emails_tobeprocessed_tuple]\n",
    "        X_predict = vectorizer.transform(X_predict)\n",
    "\n",
    "        if path.exists('supervised_model.pkl') == False:\n",
    "            model = SGDClassifier(warm_start=True)\n",
    "            model.partial_fit(X_train, y_train, classes=np.arange(1000))\n",
    "\n",
    "        else:\n",
    "            print('using pickled model')\n",
    "            \n",
    "            # Load previously saved fitted model\n",
    "            model = joblib.load('supervised_model.pkl')\n",
    "            \n",
    "            # Load previously saved fitted vectorizer\n",
    "            with open('vectorizer.pickle', 'rb') as handle:\n",
    "                new_vectorizer = pickle.load(handle)\n",
    "\n",
    "            new_X_train = new_vectorizer.transform(emails)\n",
    "\n",
    "            model.partial_fit(new_X_train, y_train)\n",
    "\n",
    "            joblib.dump(model, 'supervised_model.pkl')\n",
    "\n",
    "        folder_directory = list(model.predict(X_predict))\n",
    "\n",
    "        # Get indexes of emails that are predicted to be in an unseen category\n",
    "        unseen_labels_indexes = [i for i,x in enumerate(folder_directory) if x not in labelencoder_dict.values()]\n",
    "\n",
    "        # Delete emails with unseen labels, in reverse order so it doesn't throw off the subsequent indexes\n",
    "        for index in sorted(unseen_labels_indexes, reverse=True):\n",
    "            del emails_tobeprocessed_tuple[index]\n",
    "\n",
    "\n",
    "        # Get list of labels for emails that are predicted to be in a seen category\n",
    "        seen_labels_emails = []\n",
    "        for i in folder_directory:\n",
    "            if i in labelencoder_dict.values():\n",
    "                seen_labels_emails.append(i)\n",
    "\n",
    "        # Transform the labels back to the original encoding\n",
    "        folder_directory = list(labelencoder.inverse_transform(seen_labels_emails))\n",
    "\n",
    "        # Unzip tuple to lists\n",
    "        message_id, email = zip(*emails_tobeprocessed_tuple)\n",
    "\n",
    "        supervised_temp_df = pd.DataFrame({'message_id': message_id, \n",
    "                                           'folder_directory': folder_directory})\n",
    "\n",
    "        # Create a temporary table to store the results of supervised learning\n",
    "        supervised_temp_df.to_sql('supervised_temp', con, if_exists='replace')\n",
    "\n",
    "        # Update folder_directory in emails table and delete temporary table for supervised learning\n",
    "        cur.executescript(\"\"\"UPDATE emails_main\n",
    "                             SET folder_directory = (\n",
    "                                SELECT folder_directory \n",
    "                                FROM supervised_temp \n",
    "                                WHERE message_id = emails_main.message_id)\n",
    "                             WHERE emails_main.folder_directory IS NULL;\n",
    "\n",
    "                             DROP TABLE supervised_temp;\"\"\")\n",
    "        con.commit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.0433976650238\n"
     ]
    }
   ],
   "source": [
    "main()\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
